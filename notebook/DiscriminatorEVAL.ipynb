{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55952d30-ec1e-4559-aed0-dcf4c0ff1258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FEI\\AppData\\Local\\Temp\\ipykernel_26756\\3994017341.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  discriminator.load_state_dict(torch.load(\"../model/discriminator_epoch_10.pth\"))  # Update with the correct path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Accuracy: 75.07%\n",
      "Discriminator Sensitivity: 51.24%\n",
      "Total Misclassified Slices: 1391\n",
      "True Positives (TP): 1219, False Negatives (FN): 1160\n",
      "True Negatives (TN): 2970, False Positives (FP): 231\n",
      "Final Results - Accuracy: 75.07%, Sensitivity: 51.24%\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "from torchvision import transforms  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from PIL import Image  \n",
    "import random  \n",
    "import nibabel as nib\n",
    "import os\n",
    "\n",
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.t1_files = dataframe[dataframe[\"Scan Type\"] == \"t1\"]\n",
    "        self.seg_files = dataframe[dataframe[\"Scan Type\"] == \"seg\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t1_files) * 155\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_idx = idx // 155\n",
    "        slice_idx = idx % 155\n",
    "\n",
    "        t1_row = self.t1_files.iloc[subject_idx]\n",
    "        seg_row = self.seg_files.iloc[subject_idx]\n",
    "\n",
    "        t1_path = t1_row[\"File Path\"]\n",
    "        seg_path = seg_row[\"File Path\"]\n",
    "\n",
    "        # Skip blank slices\n",
    "        if slice_idx < 15 or slice_idx > 142:\n",
    "            return self.__getitem__((idx + 1) % self.__len__())  # Safely fetch another valid index\n",
    "\n",
    "        # Load T1 slice\n",
    "        t1_img = nib.load(t1_path).get_fdata()\n",
    "        t1_slice = t1_img[:, :, slice_idx]\n",
    "        t1_slice = torch.tensor(t1_slice, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Load segmentation slice\n",
    "        seg_img = nib.load(seg_path).get_fdata()\n",
    "        seg_slice = seg_img[:, :, slice_idx]\n",
    "        seg_label = 1 if np.any(seg_slice > 0) else 0\n",
    "\n",
    "        if self.transform:\n",
    "            t1_slice = self.transform(t1_slice)\n",
    "\n",
    "        return t1_slice, seg_label\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_discriminator_with_logging(discriminator, dataloader, device, sens=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate the discriminator on a dataset, compute accuracy and sensitivity, \n",
    "    and log misclassified slices.\n",
    "    \"\"\"\n",
    "    discriminator.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0  # Initialize counters for sensitivity calculation\n",
    "\n",
    "    output_dir = f\"misclassified_slices{sens}\"\n",
    "    # Create directory for saving misclassified slices\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    misclassified_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (t1_slice, seg_label) in enumerate(dataloader):\n",
    "            if t1_slice is None:  # Skip invalid slices\n",
    "                continue\n",
    "\n",
    "            t1_slice = t1_slice.to(device)\n",
    "            seg_label = seg_label.to(device)\n",
    "\n",
    "            # Get discriminator output (pixel-wise probabilities)\n",
    "            output = discriminator(t1_slice).squeeze()\n",
    "\n",
    "            # Compute slice-level prediction\n",
    "            slice_prediction = (output.mean() <= sens).long()  # Threshold at `sens` for slice-level classification\n",
    "\n",
    "            # Update counters for accuracy and sensitivity\n",
    "            if slice_prediction == seg_label:\n",
    "                correct += 1\n",
    "                if seg_label == 1:  # True Positive\n",
    "                    tp += 1\n",
    "                else:  # True Negative\n",
    "                    tn += 1\n",
    "            else:\n",
    "                misclassified_count += 1\n",
    "                if seg_label == 1:  # False Negative\n",
    "                    fn += 1\n",
    "                else:  # False Positive\n",
    "                    fp += 1\n",
    "\n",
    "                # Log and save misclassified slice\n",
    "                # print(f\"Misclassified Slice Index: {i}, Prediction: {slice_prediction.item()}, Ground Truth: {seg_label.item()}\")\n",
    "                save_misclassified_slice(t1_slice.cpu().squeeze().numpy(), seg_label.item(), slice_prediction.item(), i, output_dir)\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    sensitivity = (tp / (tp + fn) * 100) if (tp + fn) > 0 else 0  # Avoid division by zero\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Discriminator Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Discriminator Sensitivity: {sensitivity:.2f}%\")\n",
    "    print(f\"Total Misclassified Slices: {misclassified_count}\")\n",
    "    print(f\"True Positives (TP): {tp}, False Negatives (FN): {fn}\")\n",
    "    print(f\"True Negatives (TN): {tn}, False Positives (FP): {fp}\")\n",
    "\n",
    "    return accuracy, sensitivity\n",
    "\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"Discriminator Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Total Misclassified Slices: {misclassified_count}\")\n",
    "    return accuracy\n",
    "\n",
    "def save_misclassified_slice(slice_data, true_label, predicted_label, index, output_dir):\n",
    "    \"\"\"\n",
    "    Save a misclassified slice as an image for visualization.\n",
    "\n",
    "    Args:\n",
    "        slice_data (numpy array): The MRI slice data.\n",
    "        true_label (int): The ground truth label (0 or 1).\n",
    "        predicted_label (int): The predicted label (0 or 1).\n",
    "        index (int): Index of the slice.\n",
    "        output_dir (str): Directory to save the image.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(slice_data, cmap=\"gray\")\n",
    "    plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "    plt.axis(\"off\")\n",
    "    save_path = os.path.join(output_dir, f\"slice_{index}_true_{true_label}_pred_{predicted_label}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Load test data\n",
    "import pandas as pd\n",
    "\n",
    "test_csv_path = \"../data/selected_test_subject.csv\"  # Update with the correct path\n",
    "test_data = pd.read_csv(test_csv_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare test dataset and dataloader\n",
    "test_dataset = BraTSDataset(test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize and load the discriminator model\n",
    "discriminator = Discriminator(in_channels=1).to(device)\n",
    "discriminator.load_state_dict(torch.load(\"../model/discriminator_epoch_10.pth\"))  # Update with the correct path\n",
    "\n",
    "# Evaluate the discriminator\n",
    "accuracy, sensitivity = evaluate_discriminator_with_logging(discriminator, test_loader, device, sens=0.1)\n",
    "print(f\"Final Results - Accuracy: {accuracy:.2f}%, Sensitivity: {sensitivity:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45944624-4d6e-490c-88a9-4d1ad9bb329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Accuracy: 79.53%\n",
      "Discriminator Sensitivity: 88.52%\n",
      "Total Misclassified Slices: 1142\n",
      "True Positives (TP): 2106, False Negatives (FN): 273\n",
      "True Negatives (TN): 2332, False Positives (FP): 869\n",
      "Final Results - Accuracy: 79.53%, Sensitivity: 88.52%\n"
     ]
    }
   ],
   "source": [
    "accuracy, sensitivity = evaluate_discriminator_with_logging(discriminator, test_loader, device, sens=0.2)\n",
    "print(f\"Final Results - Accuracy: {accuracy:.2f}%, Sensitivity: {sensitivity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30c943e7-385a-442d-a9d6-58ec1b0eb40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Accuracy: 76.40%\n",
      "Discriminator Sensitivity: 95.00%\n",
      "Total Misclassified Slices: 1317\n",
      "True Positives (TP): 2260, False Negatives (FN): 119\n",
      "True Negatives (TN): 2003, False Positives (FP): 1198\n",
      "Final Results - Accuracy: 76.40%, Sensitivity: 95.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy, sensitivity = evaluate_discriminator_with_logging(discriminator, test_loader, device, sens=0.3)\n",
    "print(f\"Final Results - Accuracy: {accuracy:.2f}%, Sensitivity: {sensitivity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0652bd2e-20dd-4e50-b107-04ec9e040d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Accuracy: 72.92%\n",
      "Discriminator Sensitivity: 98.11%\n",
      "Total Misclassified Slices: 1511\n",
      "True Positives (TP): 2334, False Negatives (FN): 45\n",
      "True Negatives (TN): 1735, False Positives (FP): 1466\n",
      "Final Results - Accuracy: 72.92%, Sensitivity: 98.11%\n"
     ]
    }
   ],
   "source": [
    "accuracy, sensitivity = evaluate_discriminator_with_logging(discriminator, test_loader, device, sens=0.4)\n",
    "print(f\"Final Results - Accuracy: {accuracy:.2f}%, Sensitivity: {sensitivity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c595f494-89cd-4191-8fe6-344ac0ee54b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
